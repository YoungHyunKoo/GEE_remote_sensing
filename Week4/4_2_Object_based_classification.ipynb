{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoungHyunKoo/GEE_remote_sensing/blob/main/Week4/4_2_Object_based_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **[GEO 6083] Remote Sensing Imge Processing - Spring 2024**\n",
        "# **WEEK 4-2. Object-based image classification**\n",
        "\n",
        "### OBJECTIVES\n",
        "1. Implement image segmentation\n",
        "2. Implement object-based segmentation\n",
        "\n",
        "Credited by Younghyun Koo (kooala317@gmail.com)"
      ],
      "metadata": {
        "id": "spgKDXRFKukv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Object-based classification**\n",
        "Traditional pixel-based image classification assigns a land cover class per pixel. All pixels are the same size, same shape, and don’t consider their neighbors during the training process. However, **object-based** image classification can be useful approach to obtain more realistic classification results by grouping several pixels as *objectives*. This approach is closer to what your eyes really perceive."
      ],
      "metadata": {
        "id": "762yPdQwCsyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import ee library\n",
        "import ee\n",
        "\n",
        "# Authenticate\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize with your own project.\n",
        "ee.Initialize(project = \"utsa-spring2024\")"
      ],
      "metadata": {
        "id": "Fd9zaUXIHShv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import geemap library\n",
        "import geemap"
      ],
      "metadata": {
        "id": "WnAX3z0DCzb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import geopandas and pandas library\n",
        "import geopandas as gpd\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "EZukgApFC1AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount to Google Drive (save files)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HrCuS_fAMKKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implement Image segmentation**"
      ],
      "metadata": {
        "id": "i4QhTyHv-a6d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we will use the NAIP: National Agriculture Imagery Program data. [NAIP: National Agriculture Imagery Program](https://developers.google.com/earth-engine/datasets/catalog/USDA_NAIP_DOQQ) This data has a very fine spatial resolution (around 1 m) and consists of four bands (RGB + NIR).\n"
      ],
      "metadata": {
        "id": "R6GELfwlHZrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AOI = ee.Geometry.Polygon(\n",
        "    [\n",
        "        [-91.1028433068419, 40.810549087005384],\n",
        "        [-91.0761499627257, 40.810549087005384],\n",
        "        [-91.0761499627257, 40.82444972968615],\n",
        "        [-91.1028433068419, 40.82444972968615],\n",
        "        [-91.1028433068419, 40.810549087005384]\n",
        "     ]\n",
        ")\n",
        "\n",
        "# import image data\n",
        "dataset = ee.ImageCollection('USDA/NAIP/DOQQ')\\\n",
        ".filterDate('2014-01-01', '2014-12-31')\\\n",
        ".filterBounds(AOI)\n",
        "\n",
        "img = dataset.mean().clip(AOI)\n",
        "\n",
        "trueColor = dataset.select(['R', 'G', 'B']);\n",
        "trueColorVis = {\n",
        "  'min': 0.0,\n",
        "  'max': 255.0,\n",
        "};\n",
        "\n",
        "Map = geemap.Map()\n",
        "\n",
        "Map.centerObject(dataset, 15);\n",
        "Map.addLayer(img, trueColorVis, 'True Color')\n",
        "\n",
        "Map"
      ],
      "metadata": {
        "id": "V31YSljbKgnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will add an NDVI band as an additional band used for the classification."
      ],
      "metadata": {
        "id": "YkCL-ijrEbRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add NDVI band\n",
        "ndvi = img.normalizedDifference([\"N\", \"R\"]).rename('NDVI')\n",
        "\n",
        "Map.addLayer(ndvi, {'min':-0.5, 'max':0.5, 'palette': ['red', 'white', 'green']}, 'NDVI')\n",
        "\n",
        "Map"
      ],
      "metadata": {
        "id": "Ey47QHAYM68A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will add one more band: entropy, which represents the texture. [Image entropy](https://developers.google.com/earth-engine/apidocs/ee-image-entropy)\n",
        "\n",
        "Entropy is computed as $-Σ(p * log2(p))$, where $p$ is the normalized probability of occurrence of the values encountered in each window."
      ],
      "metadata": {
        "id": "7PFCxfCrH-BJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add entropy band\n",
        "\n",
        "square = ee.Kernel.square(radius = 4);\n",
        "\n",
        "entropy = img.select('N').toByte().entropy(square);\n",
        "Map.addLayer(entropy,\n",
        "             {'min': 1, 'max': 5, 'palette': ['red', 'blue']},\n",
        "             'entropy');\n",
        "\n",
        "Map"
      ],
      "metadata": {
        "id": "_UeeiMzmQ9o6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bands = ['R', 'G', 'B', 'N']\n",
        "FullImage = img.select(bands).float().divide(255)\n",
        "FullImage = FullImage.addBands(entropy) #.rename('entropy')\n",
        "FullImage = FullImage.addBands(ndvi) #.rename('ndvi')"
      ],
      "metadata": {
        "id": "do64LwscNRfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will conduct image segmentation. GEE has provided an image segmentation method called SNIC (Simple Non-Iterative Clustering). You can find more details about this algorithm in the following links:\n",
        "- [\"Superpixels and Polygons Using Simple Non-iterative Clustering\n",
        "Publisher\" by Radhakrishna Achanta](https://ieeexplore.ieee.org/document/8100003)\n",
        "- [ee.Algorithms.Image.Segmentation.SNIC](https://developers.google.com/earth-engine/apidocs/ee-algorithms-image-segmentation-snic)"
      ],
      "metadata": {
        "id": "PA6OnqprISQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial superpixel: Deterine the size of segments\n",
        "seeds = ee.Algorithms.Image.Segmentation.seedGrid(40);\n",
        "\n",
        "# Run SNIC image segmentation\n",
        "snic = ee.Algorithms.Image.Segmentation.SNIC(\n",
        "    image = FullImage,\n",
        "    compactness = 1,\n",
        "    connectivity = 4,\n",
        "    seeds = seeds\n",
        ")\n",
        "\n",
        "clusters_snic = snic.select(\"clusters\")\n",
        "\n",
        "# Convert SNIC result into vector polygons\n",
        "vectors = clusters_snic.reduceToVectors(\n",
        "    geometryType = 'polygon',\n",
        "    reducer = ee.Reducer.countEvery(),\n",
        "    scale = 1,\n",
        "    maxPixels = 1e13,\n",
        "    geometry = AOI,\n",
        ")\n",
        "\n",
        "# Draw outline features\n",
        "empty = ee.Image().byte()\n",
        "outline = empty.paint(\n",
        "    featureCollection = vectors,\n",
        "    color = 1,\n",
        "    width = 1\n",
        ")\n",
        "\n",
        "Map.addLayer(outline, {'palette': 'black'}, 'segments')\n",
        "\n",
        "Map"
      ],
      "metadata": {
        "id": "Wq6M0RFiM6-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert SNIC result into vector polygons\n",
        "vectors = clusters_snic.reduceToVectors(\n",
        "    geometryType = 'polygon',\n",
        "    reducer = ee.Reducer.countEvery(),\n",
        "    scale = 1,\n",
        "    maxPixels = 1e13,\n",
        "    geometry = AOI,\n",
        ")"
      ],
      "metadata": {
        "id": "OZ5_AGh5j55M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the segmentation is done! We will label these segments and use them as training datasets for a supervised classifier."
      ],
      "metadata": {
        "id": "32cwgGwPFySI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Get training samples**\n",
        "\n",
        "As we did in the previuos tutorial, we will manually digitize the training samples. Please keep in mind that we will label *segments* in this tutorial, whereas we labeled *pixels* in the previous tutorial. Here, we will define 5 classes: (1) water, (2) urban, (3) grass, (4) tree, and (5) agriculture."
      ],
      "metadata": {
        "id": "PoU6Bm3QT3Yk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) Water\n",
        "\n",
        "Please put point pins to any water segments."
      ],
      "metadata": {
        "id": "hrtI_ul5T5_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Map = geemap.Map()\n",
        "\n",
        "Map.centerObject(img, 15)\n",
        "\n",
        "Map.addLayer(img, trueColorVis, \"True color\")\n",
        "Map.addLayer(outline, {'palette': 'black'}, 'segments')\n",
        "\n",
        "Map"
      ],
      "metadata": {
        "id": "aJkxtr4_TUYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "water = ee.FeatureCollection(Map.draw_features)\n",
        "print(water.size().getInfo())"
      ],
      "metadata": {
        "id": "sMZwhrUKTUbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(2) Urban\n",
        "\n",
        "Next, let's find some urban segments. Urban class includes roads and buildings."
      ],
      "metadata": {
        "id": "MCIb-7sXUPL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Map = geemap.Map()\n",
        "\n",
        "Map.centerObject(img, 15)\n",
        "Map.addLayer(img, trueColorVis, \"True color\")\n",
        "Map.addLayer(outline, {'palette': 'black'}, 'segments')\n",
        "\n",
        "Map"
      ],
      "metadata": {
        "id": "VMuYXl8nUOKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urban = ee.FeatureCollection(Map.draw_features)\n",
        "print(urban.size().getInfo())"
      ],
      "metadata": {
        "id": "tYDlJdFvUXFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(3) Grass\n",
        "\n",
        "Next, let's find out some grass segments. Please note that you should exclude the agriculture area on the east side because we will define this agriculture site as an independent class."
      ],
      "metadata": {
        "id": "DHVa4S4vU9Le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Map = geemap.Map()\n",
        "\n",
        "Map.centerObject(img, 15)\n",
        "Map.addLayer(img, trueColorVis, \"True color\")\n",
        "Map.addLayer(outline, {'palette': 'black'}, 'segments')\n",
        "\n",
        "Map"
      ],
      "metadata": {
        "id": "tOPR2GhiTUdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grass = ee.FeatureCollection(Map.draw_features)\n",
        "print(grass.size().getInfo())"
      ],
      "metadata": {
        "id": "T8Zaaev9VAcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(4) Tree"
      ],
      "metadata": {
        "id": "xN7CTDFVVvxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Map = geemap.Map()\n",
        "\n",
        "Map.centerObject(img, 15)\n",
        "Map.addLayer(img, trueColorVis, \"True color\")\n",
        "Map.addLayer(outline, {'palette': 'black'}, 'segments')\n",
        "\n",
        "Map"
      ],
      "metadata": {
        "id": "nIxhV2hMTUgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = ee.FeatureCollection(Map.draw_features)\n",
        "print(tree.size().getInfo())"
      ],
      "metadata": {
        "id": "Cqo-3zkUVzuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(5) Agriculture"
      ],
      "metadata": {
        "id": "_MpmR4AVV89G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Map = geemap.Map()\n",
        "\n",
        "Map.centerObject(img, 15)\n",
        "Map.addLayer(img, trueColorVis, \"True color\")\n",
        "Map.addLayer(outline, {'palette': 'black'}, 'segments')\n",
        "\n",
        "Map"
      ],
      "metadata": {
        "id": "XP_OD_zkVzxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agriculture = ee.FeatureCollection(Map.draw_features)\n",
        "print(agriculture.size().getInfo())"
      ],
      "metadata": {
        "id": "MSxTNVVYVzzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the class number to each class\n",
        "def add_water(feature):\n",
        "  return feature.set(\"Class\", 0)\n",
        "\n",
        "def add_urban(feature):\n",
        "  return feature.set(\"Class\", 1)\n",
        "\n",
        "def add_grass(feature):\n",
        "  return feature.set(\"Class\", 2)\n",
        "\n",
        "def add_tree(feature):\n",
        "  return feature.set(\"Class\", 3)\n",
        "\n",
        "def add_agriculture(feature):\n",
        "  return feature.set(\"Class\", 4)\n",
        "\n",
        "water = water.map(add_water)\n",
        "urban = urban.map(add_urban)\n",
        "grass = grass.map(add_grass)\n",
        "tree = tree.map(add_tree)\n",
        "agriculture = agriculture.map(add_agriculture)"
      ],
      "metadata": {
        "id": "3QtOWNz4arqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all points into a single feature collection\n",
        "train_points = water.merge(urban).merge(grass).merge(tree).merge(agriculture)"
      ],
      "metadata": {
        "id": "zYZKD9LdVz1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the feature collection into geodataframe\n",
        "gdf_train = geemap.ee_to_gdf(train_points)\n",
        "gdf_train[\"latitude\"] = gdf_train.geometry.y\n",
        "gdf_train[\"longitude\"] = gdf_train.geometry.x\n",
        "gdf_train"
      ],
      "metadata": {
        "id": "qFj_inZqkPrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save table as csv file\n",
        "gdf_train.to_csv('drive/MyDrive/samples_object.csv')\n",
        "\n",
        "# Restore samples from csv file\n",
        "df = pd.read_csv('drive/MyDrive/samples_object.csv', index_col = 0)\n",
        "\n",
        "# Convert pandas dataframe to geopandas geodataframe (contains geometry information)\n",
        "s = gpd.GeoSeries.from_wkt(df.geometry, crs=4326) # CRS: WGS84 (latitude, longitude)\n",
        "gdf_train = gpd.GeoDataFrame(data=df, geometry=s)\n",
        "\n",
        "gdf_train"
      ],
      "metadata": {
        "id": "0xpPtJUQSL_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Train classifier in object-level**\n",
        "\n",
        "Now we have the training dataset as a geodataframe. However, since the digitized training samples have point geometries, we need to find the segment corresonding to each digitized point. We can do this by checking the spatial relationships between geopandas dataframe."
      ],
      "metadata": {
        "id": "bClWa29wJD3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the segments into geodataframe\n",
        "segments = geemap.ee_to_gdf(vectors)"
      ],
      "metadata": {
        "id": "0OKsay8hqcpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For all segments, we will find what segments contain the training points\n",
        "for i in range(0, len(segments)):\n",
        "  segment = segments.loc[i, :].geometry\n",
        "\n",
        "  # Compare with all training sample points\n",
        "  for j in range(len(gdf_train)):\n",
        "    point = gdf_train.loc[j, :].geometry\n",
        "\n",
        "    if point.within(segment):\n",
        "      segments.loc[i, \"belongs\"] = \"TRUE\"\n",
        "      segments.loc[i, \"Class\"] = gdf_train.loc[j, \"Class\"]\n",
        "\n",
        "      # break"
      ],
      "metadata": {
        "id": "JZEM4o-xqejs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Geodataframe of segments that have the intersecting training points.\n",
        "gdf = segments[segments[\"belongs\"] == \"TRUE\"]\n",
        "gdf"
      ],
      "metadata": {
        "id": "B0EDlm0B1lgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(gdf)"
      ],
      "metadata": {
        "id": "MiYcs0jdMj3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the polygon geodataframe of selected segments into earth engine feature collection\n",
        "gdf = gdf.set_crs('EPSG:4326')\n",
        "train_poly = geemap.geopandas_to_ee(gdf)"
      ],
      "metadata": {
        "id": "j7dCL9oH0_ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_areas = train_poly.reduceToImage(\n",
        "    properties = ['Class'],\n",
        "    reducer = ee.Reducer.first()\n",
        ").rename('Class').toInt()"
      ],
      "metadata": {
        "id": "Yj6YJqSg2Jlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert segmented vector into image\n",
        "predict_image = vectors.reduceToImage(\n",
        "    properties = ['label'],\n",
        "    reducer = ee.Reducer.first()\n",
        ").rename('id').toInt();\n",
        "\n",
        "FullImage = FullImage.addBands(predict_image)\n",
        "\n",
        "# Calculate mean of the segment\n",
        "FullImage_mean = FullImage.reduceConnectedComponents(\n",
        "    reducer = ee.Reducer.mean(),\n",
        "    labelBand = 'id'\n",
        ");\n",
        "\n",
        "# Calculate std of the segment\n",
        "FullImage_std = FullImage.reduceConnectedComponents(\n",
        "    reducer = ee.Reducer.stdDev(),\n",
        "    labelBand = 'id'\n",
        ");\n",
        "\n",
        "# Calculate median of the segment\n",
        "FullImage_median = FullImage.reduceConnectedComponents(\n",
        "    reducer = ee.Reducer.median(),\n",
        "    labelBand = 'id'\n",
        ");\n",
        "\n",
        "# Input image - combination of mean, std, and median of full image\n",
        "Pred_bands = ee.Image.cat([\n",
        "  FullImage_mean,\n",
        "  FullImage_std,\n",
        "  FullImage_median\n",
        "]).float()"
      ],
      "metadata": {
        "id": "n6eP8Ll4OHGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FullImage.getInfo()"
      ],
      "metadata": {
        "id": "4jEDYuYbNaU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Apply classifier to the segmented polygons**\n",
        "\n",
        "We will use Random Forest classifier for this example. [ee.Classifier.smileRandomForest](https://developers.google.com/earth-engine/apidocs/ee-classifier-smilerandomforest)"
      ],
      "metadata": {
        "id": "stia1aiCI0Ob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training images\n",
        "clip_Image = Pred_bands.clip(train_poly)\n",
        "\n",
        "train_areas = train_areas.addBands(clip_Image)\n",
        "\n",
        "predictionBands = Pred_bands.bandNames();\n",
        "\n",
        "classifierTraining = train_areas.select(predictionBands).sampleRegions(collection = train_poly, properties = ['Class'], scale = 2);\n",
        "\n",
        "# Train random forest classifier\n",
        "RF = ee.Classifier.smileRandomForest(50).train(features = classifierTraining, classProperty = 'Class', inputProperties = predictionBands);\n",
        "\n",
        "# Apply random forest classifier\n",
        "classified_RF = Pred_bands.select(predictionBands).classify(RF);\n",
        "\n",
        "print(\"Classification has been done!!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "g8EUTEQE2jE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Map = geemap.Map()\n",
        "\n",
        "Map.centerObject(dataset, 15);\n",
        "\n",
        "Map.addLayer(img, trueColorVis, 'True Color')\n",
        "\n",
        "vis_RF = {'min': 0, 'max': 4, 'palette': [ 'blue', 'red', 'orange', 'green', 'yellow']}\n",
        "\n",
        "Map.addLayer(classified_RF, vis_RF, \"OBIA_RF\");\n",
        "Map"
      ],
      "metadata": {
        "id": "7B9PO5w32Jn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "- https://joaootavionf007.medium.com/object-based-image-analysis-on-google-earth-engine-1b80e9cb7312"
      ],
      "metadata": {
        "id": "LlhmFRm-W8LJ"
      }
    }
  ]
}